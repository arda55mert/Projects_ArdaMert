# Projects_ArdaMert

Here's a description for each of the files based on your explanation:

BERTModel.ipynb:
This Jupyter notebook utilizes BERT (Bidirectional Encoder Representations from Transformers) to classify comments as insightful or not. The model is fine-tuned to distinguish between insightful and non-insightful comments, using manually labeled data for training and validation. The project also compares the BERT model's performance with human-labeled insights, providing a benchmark for model accuracy and effectiveness.

Trend_backend.py:
This is the backend portion of a full-stack application developed to classify customer and viewer opinions on various platforms such as news, e-commerce, and online communities. It leverages LLM models and prompt engineering to generate insightful summaries. The backend is built using FastAPI for API development, enabling multiple endpoints to process and return classifications and summaries in real-time.

Trend_frontend.py:
This file contains the frontend of the full-stack application built using FastHTML, responsible for the user interface where users can input opinions or data and receive classifications or summaries. It connects with the backend (Trend_backend.py) to display outputs generated by the LLM models. Docker was used for deployment, ensuring the application runs in a containerized environment, and web scraping was utilized to collect data for analysis.

NBA_Project.Rmd:
This R project explores how college basketball statistics correlate with NBA player success. The analysis focuses on two key questions: (1) How early will a player be drafted based on their college statistics? and (2) Which players will eventually become NBA All-Stars based on their college performance? The project involves data collection, statistical analysis, and predictive modeling to answer these questions.

StockMarket-MachineLearningModel:
This project involved building a supervised machine learning model to help a bank increase its share volume in the stock market by 2%. The model was trained using a year's worth of customer data to provide precision targeting recommendations. Technologies used include SQL for data management, SparkConf for big data processing, and machine learning models like Optuna and XGBoost for optimization and prediction.
